\documentclass[11pt]{sdm}
\usepackage{xcolor}
\usepackage{float}
\usepackage[utf8]{inputenc} 
\usepackage{indentfirst}
\usepackage{listings}
\usepackage{hyphsubst}
\usepackage{amsmath}

				  
\lstdefinestyle{customc}{
  belowcaptionskip=1\baselineskip,
  breaklines=true,
  frame=L,
  xleftmargin=\parindent,
  language=C,
  showstringspaces=false,
  keywordstyle=\bfseries\color{green!40!black},
  commentstyle=\itshape\color{purple!40!black},
  identifierstyle=\color{blue},
  stringstyle=\color{orange},
}

\lstset{escapechar=@,style=customc,numbers=left,literate={~} {$\sim$}{1}}


%Number the pages
\pagestyle{plain}

\title{Software Fault Isolation using the CompCert compiler}
\author{Alexandre \textsc{DANG}}
\supervisorOne{Frédéric \textsc{Besson}}
\team{Team CELTIQUE}

\school{supelec}

\domain{Domaine: Cryptography and Security}

%write your abstract here
\abstract{}

\begin{document}
\maketitle

%*****************************************************************%

\section{Introduction}


\begin{itemize}
	\item Secure malicious code through software solution
	\item Usage in applications which use modules from unknown origin (browsers, computer clusters)
	\item current appeal for SFI speed and small TCB
	\item SFI is still incomplete, especially with ROP attack => our approach
	\item  plan
\end{itemize}


\newpage
\section{\textit{Software Fault Isolation}}
\label{sec:sfi}

	We introduce here \textit{Software Fault Isolation} (SFI) which inspired us the idea to protect return addresses through fixed stack frame size. SFI aims to protect a main program from the different modules that he will need to use. These modules will be loaded in the same memory space as the main program but in a confined area called \textit{sandbox}. The SFI mechanism is composed of two elements: a code generator and a verifier. The generator transforms the assembly code of the hazardous modules so that they will be constrained in the sandbox. The verifier operates just before loading the modules in the memory. It checks the if SFI transformations introduced by the generator are still present and valid. For the rest of the document we will reserve the word ''program'' to refer to the code protected by SFI and ''module'' to refer to the hazardous code.

\subsection{Principle}

The main principle behind SFI was first presented in the work of Wahbe and al. \textcolor{green}{ref}
. Later works \textcolor{green}{ref}, which will be introduced in Chapter~\ref{ssub:Implementations}, are all based on the foundations of SFI detailed here.
The implementation described here was realised for a RISC architecture like MIPS or \textit{Alpha}.

SFI considers that a malicious code is effectively contained in the sandbox if these three security properties hold true:
\begin{itemize}
	\item \textbf{Verified code}, only instructions that have been checked by the verifier will be executed 
	\item \textbf{Memory safety}, malicious modules will not do any \textit{write} or \textit{jump} operations out of the sandbox
	\item \textbf{Flow control integrity}, every flow control transfer from hazardous modules to the main program is identified and verified
\end{itemize}
The first property protects us against self-modifying code which could bypass the SFI measures. \textit{Memory safety} prevents any illegal access to the memory of the protected program. The last property allows us to authorized only licit interactions between the program and its modules. SFI forbids any call from malicious modules that could modify the flow control of the program. If the flow control was fiddled with, it could lead to an unexpected behaviour of the program which we want to avoid.

The code generator transforms the assembly code of the hazardous modules so that respect the security properties presented before. The generator is integrated to the compiler which will create \textit{sandboxed executable}. Afterwards this executable will be checked by the verifier before being loaded in the memory. 
It verifies that the transformations introduced by the generator are present and valid. If the verification fails the module will be rejected and will not be executed. We can note that we only need to trust the verifier to prevent running any dangerous module. It is one advantage of SFI, only the verifier needs to be in the \textit{Trusted Computing base} (TCB).


\subsubsection{Code generator}
\label{ssub:Code generator}
To protect the program from its modules, the generator will restrain every write and jump instructions of the modules to addresses of their sandbox.
The generator has to face three issues to do so. Firstly, is to introduce protection mechanisms before every dangerous instructions. For example, assessing that the address of a jump instruction is an authorized one.
Secondly, we have to make sure that these protection mechanisms can't be avoided. 
Finally, the transformations introduced have to authorized only legal calls out of the sandbox by using entry points specified by the protected program. For example, Google Chrome only allows its modules to use a specific interface to interact with the browser. This way the modules can't disrupt the flow control of Google Chrome easily.
\paragraph{Confining memory accesses.}
\label{par:Confining memory accesses}
The main program memory should avoid being corrupted by its modules. SFI aims to isolates these modules in a reserved of the program's memory called sandbox.
The sandbox is a contiguous memory area which size is a power of two. Indeed, these requirements eases the confinement of the modules in their sandbox by using arithmetic operations on bits which accelerates the process.
\paragraph{Protection of sandboxing mechanisms.}
\label{par:Protection of sandboxing mechanisms}
\paragraph{Controlled interactions with the protected program.}
\label{par:Controled interactions with the protected program}

\subsubsection{Code verifier}
\label{ssub:Code verifier}

\subsubsection{Pros and cons}
\label{ssub:Pros and cons}

\subsubsection{Implementations}
\label{ssub:Implementations}
\paragraph{NativeClient, SFI for Google Chrome.}
\label{par:NativeClient, SFI for Google Chrome}


\subsection{SFI using CompCert}
\label{sub:sfi_comp}


\subsubsection{CompCert the verified compiler}
\label{ssub:CompCert the verified compiler}
\paragraph{CompCert.}
\label{par:CompCert}
\paragraph{Memory model of CompCert.}
\label{par:Memory model of CompCert}


\subsubsection{SFI with CompCert}
\label{ssub:SFI with CompCert}
\paragraph{Cminor.}
\label{par:Cminor}
\paragraph{Specification of the SFI transformation.}
\label{par:Specification of the SFI tranformation}
\paragraph{Masking in CompCert.}
\label{par:Masking in CompCert}




\subsubsection{Evaluation of the approach}
\label{ssub:Evalutation of the approach}

\subsection{Limits of SFI}
\label{sub:Limits of SFI}
\subsubsection{Return addresses}
\label{ssub:Return addresses}
\subsubsection{Proposed solution}


\newpage
\section{Overview of the approach}
\label{sec:Overview of the approach}
	Many attacks on software aims at diverting the control flow of the targeted program. Among those, \textit{Returned Oriented Programming} (ROP) attacks specifically try to overwrite the return addresses.
By doing so the attacked function will return to a malicious piece of code that will get executed.
Stack overflow is an example of such ROP attacks.
We propose a solution against ROP attacks which combined with SFI would protect from most of control-flow interference attacks.
Inspired from SFI techniques we aim to prevent any overwriting of the return addresses. To do so we need to know these return addresses locations in the memory. Therefore our approach consists of modifying the stack structure in order to have a way to distinguish the return addresses locations. With this knowledge we will be able to put a mask, as in SFI, before every dangerous write instructions and prevent any ROP attack.

\subsection{ROP attack}
\label{sub:Issue}

	We want to protect our program against ROP attacks. These attacks are directed against the stack and especially the function return addresses located in the stack.
We will begin by a short introduction about the mechanisms behind the stack. Then we will explain how ROP attacks work with the example of a classical buffer overflow.

\subsubsection{The stack}
\label{ssub:The stack}
	The stack is a specific area of the memory of a program. The memory allocated to a program is divided among multiple areas like the stack (which we are going to detail), the heap (where we put dynamically allocated or global variables) and the code is also allocated in a specific area.
The stack is composed of frames and each of them are related to a function being executed. Frames are piled up on the stack following the FIFO rule (\textit{First In First Out}). Explicitly, every time a function is called, a new frame is created and placed on the top of the stack. Reciprocally when a function terminates its frame will be popped out of the stack.
Frames contain multiple kind of data related to their function like local variables, parameters of the function and return addresses. Return addresses indicates the point of execution to return to after a function terminates. When popping a frame the program is supposed to execute the code at the address matching the value contained in the return address.
ROP attacks aims to overwrite these return addresses which enables them to execute malicious code hidden in another part of the memory instead of continuing the normal flow of the program.

\subsubsection{Buffer overflow}
\label{ssub:Buffer overflow}

Stack overflows are the most popular ROP attacks \textcolor{green}{ref} . In Figure~\ref{buffer_overflow_code} we can see an example of buffer overflow written in C.
The goal of this code is to execute the function called \textit{evil\_code()} which just prints ``Argh, we got hacked!\textbackslash{n}'' line~6 of Figure~\ref{buffer_overflow_code}. The function \textit{evil\_code()} should not be executed in our program, we suppose it is never called.
The code was compiled with \textit{gcc -m32 -fno-stack-protector} to remove all stack protections used by gcc. The output of the code of the successful buffer overflow can be seen in Figure~\ref{output_buffer}.
\begin{figure}[!ht]
\begin{lstlisting}
void evil_code() {
	printf("Argh, we got hacked!\n");
}

void foo(char* input){
	char buf[1];
	... code ...
	strcpy(buf, input);
	... code ...
}
\end{lstlisting}
\centering
\caption{Example of buffer overflow in C}
\label{buffer_overflow_code}
\end{figure}

We printed out the stack before and after the attack to have a better comprehension of the attack.
We see in the Figure~\ref{output_buffer} the consequences of the buffer overflow in red. The stack was overwritten and the return address was modified to the address of \textit{evil\_code()} which code was successfully executed.

The vulnerability resides in the function \textit{strcpy} line~8. \textit{strcpy} just copies characters one by one until it finds ``0''(which corresponds to the end of a string) in the source string. However our source string can contain many more characters than \textit{buf} is supposed to have. 
Indeed \textit{buf} is declared line~6 as an array of 1 character and our source string is the argument that we give to the program.
If the source string is bigger than the destination \textit{strcpy} will just continue to write the source string over others variables location in the stack and possibly reach the return address.
The variable \textit{input} has the value of the parameter we give to our program and is the string we are supposed to copy in \textit{buf}.
After few tries and fails we found the correct parameter to successfully do the buffer overflow. This input can be seen on the first line of Figure~\ref{output_buffer} which is \textit{python -c 'print 13*"a"+"\textbackslash{x7b}\textbackslash{x84}\textbackslash{x04}\textbackslash{x08}}` or \textit{aaaaaaaaaaaaa\textbackslash{x7b}\textbackslash{x84}\textbackslash{x04}\textbackslash{x08}}\\
In our example we filled the stack with ``a'' which corresponds to ``61'' in ASCII until we reached the return address.
We can see the consequence of the attack in the output Figure~\ref{output_buffer}, where the stack is full of ``61'' after executing \textit{strcpy}.
When we reached the return address we overwrote it with the address of \textit{evil\_code} which was \texttt{0x0804847b} given on the second line of Figure~\ref{output_buffer}.
This way, the next instruction that will be executed after \textit{foo} finishes will be the function \textit{evil\_code}.
At the end of the program we can see that we get a \textit{Segmentation fault (core dumped)}, which is normal because we messed up the stack when we overwrote is with ``a''. But since we managed to execute \textit{evil\_code} the attack is still successful. \hfill \break

Even though the buffer overflow was a basic one, it still happens to see the usage of vulnerable functions like \textit{strcpy} in the industry.
Furthermore there are much more sophisticated ROP attacks which are much more effective as witnessed by security vulnerability reports.
Before, classic ROP attacks tried to execute some malicious code that was inserted manually in the stack or in the heap. But nowadays most system render their stack and their heap non executable which prevents the classic ROP attacks.
However modern ROP attacks are now able to create malicious code from different pieces found in the program or in the libraries used. The most famous one is called \textit{return-to-libc} attack which pieces of code from the \textit{libc} library to create malicious code. Then the attacker still try to deviate the control flow of the program through return addresses to the malicious code just assembled with \textit{libc} code.

\begin{figure}[!ht]
\textcolor{gray}{terminal\$~} ./buffer \$(python -c 'print 13*"a"+"\textbackslash{x7b}\textbackslash{x84}\textbackslash{x04}\textbackslash{x08}"') \\
\textcolor{red}{Address of evil\_code = 0x0804847b} \\
Stack before: \hfill \break
0xf7712000    \hfill \break
0xff957998    \hfill \break
0xf7593d26    \hfill \break
0xf7712d60    \hfill \break
0x0804868c    \hfill \break
0xff957978    \hfill \break
0xf7593d00    \hfill \break
0xf7713dc0    \hfill \break
0xf77828f8    \hfill \break
0xff957998    \hfill \break
0x08048510    ~~~~~~~~~~~~~~~~\textcolor{blue}{//Return address of \textit{foo}}\hfill \break
              \hfill \break
Stack after : \hfill \break
0xff958161    \hfill \break
0xff957998    \hfill \break
0xf7593d26    \hfill \break
0xf7712d60    \hfill \break
0x0804868c    \hfill \break
0xff957978   			   ~~~~~~~~~~~~~~~~\textcolor{blue}{//Buffer overflow}\hfill \break
\textcolor{red}{0x61}593d00~~~~~~~~~~~~~~~~\textcolor{blue}{//``a''   } \hfill \break
\textcolor{red}{0x61616161}~~~~~~~~~~~~~~~~\textcolor{blue}{//``aaaa''} \hfill \break
\textcolor{red}{0x61616161}~~~~~~~~~~~~~~~~\textcolor{blue}{//``aaaa''} \hfill \break
\textcolor{red}{0x61616161}~~~~~~~~~~~~~~~~\textcolor{blue}{//``aaaa''} \hfill \break
\textcolor{red}{0x0804847b}~~~~~~~~~~~~~~~~\textcolor{blue}{//"\textbackslash{x7b}\textbackslash{x84}\textbackslash{x04}\textbackslash{x08}",  \textit{evil\_code} address \\}
\\
Argh, we got hacked! ~~\textcolor{blue}{//Success! \textit{evil\_code} was executed}\\
Segmentation fault (core dumped)
\caption{Output from buffer overflow example}
\label{output_buffer}
\end{figure}


\subsection{Description of the approach}
\label{sub:Description of the approach}
	We want to protect programs against ROP attacks like the buffer overflow seen previously. We want to prevent any return address from being overwritten illegally. The only moment they should be written over is during a function call routine.
We want to be able to add runtime checks in the code like SFI, therefore we need to be able to check if an address is the location of a return address. 

The biggest difficulty is to be able to know if a location in the stack corresponds to a return address or not. Indeed the stack grows through function calls which pile up stack frames. 
These frames are constructed dynamically depending of the function, hence the locations of return addresses are not easily known.
As it is we do not have enough information to correctly protect return addresses since we do not know precisely where they are located.

Several solutions exists against this issue. We could for example add a lot of meta-data during the compilation to have extra information and then effectively protect the return addresses. Another solution is to create a second stack called \textit{shadow stack}. We would then have complete control over the \textit{shadow stack} which allows us defend against ROP attacks.
\textcolor{green}{maybe expose the cons of these approaches from our point of view}

Our solution is to modify the current stack structure to be able to know the return addresses locations easily. The main idea is to fix a constant offset $n$ between return addresses allowing us to exactly know where a return address is located relative to the others. We will explain thoroughly the approach that we want to apply in the following section.

\subsubsection{Proposed solution}

\paragraph{Fixing return addresses locations and stack alignment.}
\label{par:Fixing return addresses locations}

We want to be able to decide if a pointer points to a return address at runtime. With this knowledge we will be able to detect if an instruction may compromise our program.
The idea is to modify the stack layout in order to have a constant offset $n$ between neighbouring return addresses. This way we know that the neighboring return addresses are always located at a distance $n$ from a frame return address. Furthermore all the other return addresses are separated by a distance which is necessarily a multiple of $n$.
For example suppose that we know the location of a return address, we call this location $c$.
Since all neighboring return addresses are separated by the exact amount $n$, we know that the following return addresses locations will be $c+k*n$ with $k>0$. Reciprocally the previous return addresses will be located at $c-k*n$ with $k>0$.\\
Thus we can generalize the two previous relations and for every return address location \textit{a} we will have the relation $a~mod~n = c$.

The next hurdle is to choose $n$ and $c$ cleverly. 
For $n$, the most important thing is that frames have enough space to store all the needed data. Therefore we define the value of $n$ as the biggest frame size of all the functions in a program.
If the return addresses are separated by this amount we are sure that every function will have enough space in the stack for its frame. \\
Afterwards we have to define $c$. The best way that we found is to modify the stack in order to have the first return addresses location to be equal to $c$. If we are able to do such a thing, we can also easily define the value of $c$ and for simplicity we would like to have $c~mod~n = 0$

The Figure~\ref{idea_stack} pictures the transformation we want to apply to the stack. On the left we have represented an usual stack with return addresses all over the place.
Since these locations are almost random it's really difficult to pinpoint their location. After transforming the stack (stack on the right) we can see that the different addresses are separated by the same constant $n$.

We have two relations about return addresses location:
$$[\forall a\in Ret\_locations,~a~mod~n=c]\text{ and }[c~mod~n=0]$$
$Ret\_locations$ is the set containing all the locations of return addresses.
We can combine our two properties and we obtain:
{\Large $$\forall a\in Ret\_locations,~a~mod~n=0$$}



\begin{figure}[!ht]
\centering
\includegraphics[scale=0.6]{images/idea_stack.pdf}
\caption{Stack modifications}
\label{idea_stack}
\end{figure}

\paragraph{Detection of dangerous instructions.}
\label{par:Detection of dangerous instructions}

The second step is to detect every possibly harmful instructions to return addresses. We consider as dangerous every instruction that can freely write to the memory. Our approach is mainly related to the C language.
In C, instructions that fit such criteria are assignment to pointer dereference in the form of  \textit{(pointer)*~=~value} or \textit{(pointer+offset)*~=~value}. \\
In the previous example of buffer overflow Figure~\ref{buffer_overflow_code}, the vulnerability resides in the function \textit{strcpy} line~12. To pinpoint the dangerous instruction let's check the source code of \textit{strcpy} Figure~\ref{strcpy} from Apple.
We can see in the \textit{while} loop line~10 that \textit{strcpy} copies characters one by one from the source string \textit{s2} to the destination \textit{s} until it finds a character equals to \textit{0}.
To copy the characters, \textit{s} and \textit{s2} are pointers which initially point to the memory area of the destination and the source string. Then until it finds a character matching \textit{0} the value pointed by \textit{s2} is copied to the location pointed by \textit{s} and the pointers are incremented. The harm happens when the source \textit{s2} is much longer than the destination. In this case we continue to copy to the location pointed by \textit{s} even if the memory written to does not belong to the destination string anymore.\\
In this example we see clearly that it's the pointer dereferencing that allows one to write directly in the memory. For that reason we target such type of instructions in our approach.

\begin{figure}[!ht]
\begin{lstlisting}
char * strcpy(char *s1, const char *s2) {
	char *s = s1;
	while ((*s++ = *s2++) != 0)
		;
	return s1;
}
\end{lstlisting}
\centering
\caption{\textit{strcpy} source code from Apple}
\label{strcpy}
\end{figure}

\paragraph{Securing dangerous statements.}
\label{par:Protection around dangerous statements}

Finally when we have detected all the dangerous statements we transform the module code. Before each of this dangerous statement we add a protection mechanism similar to masking in SFI. The algorithm of the check is represented in Figure \ref{runtime_check}: \\
	\begin{enumerate}
		\item We check if the address is in the stack. Return addresses only exist in the stack, we do not need to concern ourselves with the other accessible memory area: the heap.
		\item If the address is in the stack we check if the target address $a$ verifies our equality $a~mod~n=0$. If it does then it's a return address location.
		\item If a target address abides by the two previous condition, it's an illegal instruction and we make the program crash. If it does not then the program just continue to run like normal.
	\end{enumerate}
We want our implementation to respect the property of transparency, if a program is safe then our transformation does not modify its behaviour.

\begin{figure}[!ht]
\centering
\includegraphics[scale=0.6]{images/runtime_check.pdf}
\caption{Runtime check algorithm}
\label{runtime_check}
\end{figure}

\hfill \break 
	To sum it up, our approach aims to have an easy way to know return addresses location and then add a check at runtime before every dangerous instruction to prevent illegal writing on return addresses location.
To do this we divided the approach into four phases:
\begin{enumerate}
	\item Fix stack frames size
	\item Align the stack
	\item Detect dangerous statements
	\item Secure the dangerous statements
\end{enumerate}


\subsection{Security properties}
\label{sub:Security properties}
	The approach we propose is composed of four phases, to get the confidence that our idea is effective in protecting return addresses we are going to formalize the properties we expect from each phase. 
Furthermore like we pointed earlier, we are going to work with the certified compiler CompCert.
The ideal way to be sure of our idea would be to prove it with Coq the proof assistant the language used to build CompCert.
By working with these tools we hope that eventually we will be able to prove some security guarantees brought by our approach.

\begin{enumerate}
	\item \textbf{Fixed stack frames size}
		\begin{itemize}
			\item Return addresses locations are all separated by a constant offset bigger or equal to any frame of the stack
		\end{itemize}
	\item \textbf{Stack alignment}
		\begin{itemize}
			\item The first return address location of the program has its least significant bits equal to 0
		\end{itemize}
	\item \textbf{Detection of memory write statements}
		\begin{itemize}
			\item Every statement of the analysed code that might modify the stack memory state is detected
		\end{itemize}
	\item \textbf{Securing memory write statements}
		\begin{itemize}
			\item The protection will trigger an error behaviour if we try to write on a protected address
		\end{itemize}
\end{enumerate}

Combined, properties 1. and 2. give us the guarantee that the least significant bits of all the return addresses location will verify $a~mod~n=0$ with $n$ the fixed offset between return addresses.
Basically we make it so the protection mechanism prevents any write on addresses located in the \textbf{stack memory area} and verifying $a~mod~n=0$.

\hfill \break 
Another property we did not mention yet is that all our transformations need to be transparent. In other words, if we apply our methods on a program which is already safe then its behaviour is not affected. We will explain how we ensure this property more thoroughly in Chapter~\ref{sec:implementation}.

\hfill \break 
For these properties to always hold true we need to place some conditions which we are going to list in the following section. Our approach guarantees that if all the properties mentioned are fulfilled the program will be protected against any ROP attack.

\subsection{Analysis of the approach}
\label{sub:Analysis of the approach}

\subsubsection{Conditions}
\label{ssub:Conditions}

The solution we have just presented can bring very strong security properties against ROP attacks. However for this approach to work we need certain hypothesis to be true. Indeed some of the properties enumerated before are invalidated after certain operations.

\paragraph{Stack modifications.}
\label{par:Stack modifications}
Every operation that disrupts the stack structure may nullify our property that says ``every return addresses are separated by a fixed offset''. For example x86 architecture use the ESP register to keep track of the stack growth. If we fiddle with it we may introduce a shift in the return addresses location. Then our runtime check of the return addresses locations property $a~mod~n=0$ would not be relevant anymore.
		For example, the Figure~\ref{inline_assembly} shows a piece of inline assembly which disrupts the stack line~2. Inline assembly allows one to put some assembly code in the middle of C code. Here the assembly decrements the stack pointer stored in ESP. By doing so the stack will be shifted by an amount of 50 bytes and our formula to the locations of return addresses will not be correct anymore.

\paragraph{Insecure libraries.}
\label{par:Insecure libraries}

For our approach to work we need to have all dangerous write statements to contain our runtime checks. Hence all executed code must have been compiled with our transformation. For example, the \textit{glibc} library of C contains multiple insecure functions like \textit{printf, strcpy\dots} Furthermore those flawed functions are common vulnerabilities for \textit{buffer overflows} attacks which are a type of ROP attack. To avoid this issue we would need to rewrite the glibc or compile it with our tools.

\paragraph{Modules need the same offset.}
\label{par:Modules need the same offset}
If a program uses multiple modules or library they need to be compiled with the same offset $n$. Indeed if the offset of the different modules are different we cannot use the previously defined relation $a~mod~n=0$ cannot be used anymore. Thus it is not possible to easily know if a location corresponds to a return address.

\begin{figure}[!ht]
%asm(''sub $50, %esp'');
\textcolor{green}{TODO substitute with the right syntax when finished}
\begin{lstlisting}
int foo(int a) {
	asm(``\$sub 50, \%esp'');
	//This line does the operation ESP = ESP - 50
	//This disrupts the stack layout we establish in our transformation
	printf("Hello world!");
}
\end{lstlisting}
\centering
\caption{C inline assembly}
\label{inline_assembly}
\end{figure}

\subsubsection{Discussion}
\label{ssub:Discussion}
	We have presented the principle of our approach in this chapter. Then we mentioned some necessary conditions for our solution to work properly. In this section we are going to discuss about the pros, cons or remarks about the proposed solution.

	The benefits of our transformation is clear, any code compiled with a compiler enforcing our methods is unable to interfere with the control flow of our program through return addresses.
	Furthermore if we combine our solution with the SFI presented earlier we can have some strong security properties on the execution of dangerous modules with our main program.
Our approach may also have some impact on portability and efficiency:

\paragraph{Architecture dependant.}
\label{par:Architecture dependant}
Our solution depends a lot of the stack layout of the program.
Indeed fixing the size of the frames requires us to modify the original stack layout.
Therefore since the stack layout vary depending of the architecture and compiler you are using, the modifications that have to be done are also different.
We can then easily comprehend that we would need a different implementations for every existing stack layout.
Moreover since these layouts can be really different it might be quite complicated to implement our solution on certain of them.
In the implementation we present after we focus solely on x86-32 architecture with the compiler CompCert.

\paragraph{Memory consumption.}
\label{par:Memory consumption}
Since we are fixing the size of the frames instead of having dynamic sizes the memory usage of the stack is bigger. We have the issue of choosing an adequate size for the frames in our solution. The easiest one is to take the maximum frame size of the program as the constant size for all the frames. The downside is that we might have a memory usage explosion from our stack.
We did not encounter any issue about memory during the tests we did but the impacts may be visible on especially big programs. It might be interesting to study the efficiency of our approach on the growth of the stack.

Despite the cons presented we believe the benefits we gain from this method is worth it.
We are going to present in the following section the implementation we made based on the ideas we introduced here. This implementation was made with the compiler CompCert for the x86-32 architecture. We are targeting programs written in C, which explains that all the examples we used were related to the C language.


\newpage
\section{Implementation}
\label{sec:implementation}

For the implementation we work with the compiler CompCert. CompCert already had an implementation of SFI presented earlier. Thus if we could combine our approach with the SFI, any program compiled with CompCert would have strong security guarantees. Furthermore CompCert is written with Coq the proof assistant, we eventually hope that we will be able to prove these security properties. In this section we are going explain in details how we implemented the approach and the different choices we did during the process. Afterwards we will discuss these choices and evaluate the results and performances obtained.

\subsection{Implementation}
\label{sub:Implementation}
	Our approach is separated in four phases: ``Fixed stack frames size'', ``Stack alignment'', ``Detection of memory write statements'' and ``Evaluation of the implementation''. We are going to detail the implementation of these phases in the following sections. These transformations are deeply linked to the stack layout, hence to have a better understanding we are going to start by introducing the CompCert stack structure.

\subsubsection{CompCert stack}
\label{ssub:CompCert stack}
	The layout of the stack is dependent of the architecture and the compiler/interpreter used. For the sake of comprehension of the future sections we describe here the stack layout of x86-32 in CompCert.
The stack layout of CompCert x86-32 is pictured in Figure~\ref{stack_layout}.
First of all we can notice that the stack grows downwards, it means that the stack grows from the highest addresses to the low ones.
As we can see the usual data are stored in this stack like local variables, parameters, register states and the return address.

\begin{figure}[!ht]
\centering
\includegraphics[scale=0.55]{images/stack_layout.pdf}
\caption{CompCert x86-32 stack layout}
\label{stack_layout}
\end{figure}

Each frame is built when a function is called, the different steps related to the creation of a frame is called \textit{function call routine}.
CompCert function call routine is described in the Figure~\ref{call_routine}. Each phase of the function call routine of the Figure~\ref{call_routine} is explained just here:
\begin{enumerate}
	\item Write the return address
	\item Allocate enough memory for the rest of the stack frame
	\item Save registers states in the stack
	\item Execute the function body (use the memory for local and stack data)
	\item When calling another function, place its parameters at the end of the stack and repeat the process
\end{enumerate}

\begin{figure}[!ht]
\centering
\includegraphics[scale=0.55]{images/call_routine.pdf}
\caption{CompCert function call routine}
\label{call_routine}
\end{figure}

When returning from a function, the return routine is pretty much the opposite:
\begin{enumerate}
	\item Restore registers state
	\item Deallocate the stack until the return addresses
	\item Pop the return address memory and jump to the value stored in it
\end{enumerate}


\subsubsection{Fixed stack frames size}
\label{sub:Fixed stack frames size}
During this phase we want to ensure these two properties:
\begin{itemize}
	\item Return addresses locations are all separated by a constant offset bigger or equal to any frames of the stack
\end{itemize}

\paragraph{Fix the frames size.}
\label{par:Fix the frames size}

Fortunately in the function call routine of CompCert the return addresses are always at the top of their frames.
This particularity makes the task easier, indeed, since the location of the return address is fixed in the stack we can simply fix the size of the frames to have a constant offset between the return addresses. \\
To fix the size of stack we had to find the description of the stack in CompCert. Then we just had to put a constant in the attribute \textit{size} of the stack and readjust the alignment of the different parts of the frames. We told CompCert to keep the return address of the stack as the first location in the frame and that all the extra space introduced by the fixed size will be taken for  \textit{stack data and locals}. The remaining parts of the frame keep the same size as before.

\begin{figure}[!ht]
\centering
\includegraphics[scale=0.6]{images/frame_transform.pdf}
\caption{Transformation of CompCert frame}
\label{frame_transform}
\end{figure}

In Figure~\ref{frame_transform}, we present the transformation of the CompCert frame to a new frame with a fixed size equal to $n$. We can see that the stack data and locals part have increased and push the other parts further in the bottom.


\paragraph{Choice of frames size.}
\label{par:Choice of frames size}

We chose to limit the choice of the frames size to powers of two. Indeed, since addresses are written in binary having a power of two as constant offset will ease the runtime checks implementation. Indeed by using powers of two, all the return addresses will have the same least significant bits. For example if the first return address location is \texttt{0xffffff910} (in hexadecimal) and our constant frame size is $2^8 = \texttt{0100}$ (in hexadecimal). Then all the following return addresses locations will be \texttt{0xfffff810} (the stack grow downwards), \texttt{0xfffff710}, \texttt{0xfffff610}\dots And their least significant bits are actually always equal to \texttt{10}. This particularity will help during the phase of runtime checks that we will explain in Section~\ref{ssub:implem_check_address}.

To prevent having compiled programs with too small stack frame, we added in CompCert a check. This test verifies that the chosen size is bigger than any dynamically calculated one. If not, the compilation fails. This way the chosen size corresponds to the smallest power of two which is bigger or equal to any dynamically calculated frames size of the program.

We can see in Figure~\ref{stack_transform} the effect of our implementation. 
The left stack is the usual layout of CompCert stacks with the return addresses located at the top of the frames. We call $F_{size}$ the size of the biggest frame of the whole program.

For our transformed stack we have to chose a fixed size for the frames and it needs to be a power of two, bigger or equal to $F_{size}$. In Figure~\ref{stack_transform} we chose $2^8$ to continue the examples we gave before.
We can see that the stack on the right has fixed size frames equal to $2^8$ and the return addresses are all separated by the same offset dues to CompCert stack layout.
The implementation effectively fulfills the property of having constant offset between return addresses.
Furthermore we can see that the location of the return addresses are \texttt{0xfffff910}, \texttt{0xfffff810}, \texttt{0xfffff710}\dots
Hence all the return addresses have the particularity of always having the same least significant bits (\texttt{10}). This particularity will be used later for the implementation of the protection mechanism.

\begin{figure}[!ht]
\centering
\includegraphics[scale=0.6]{images/stack_transform.pdf}
\caption{Fixing the size of CompCert stack frames}
\label{stack_transform}
\end{figure}

\subsubsection{Stack alignment}
\label{ssub:Stack alignment}

The implementation in this section has to do a transformation that makes the following property true:
\begin{itemize}
	\item The first return address location of the program has its least significant bits equal to 0
\end{itemize}

\paragraph{ASLR.}
\label{par:ASLR}

This property was hard to make true because of the existence of ASLR that we talked about before. Indeed since there is randomization of the stack addresses we needed to find an operation that could align the stack correctly for any initial location of the stack. ASLR randomizes partially the addresses, for example the beginning address of the stack always has the following format \texttt{0xff*****0}. 
ASLR keeps the eight most significant bits so the different memory areas like the stack are still contained in their reserved area. The four least significant bits of a new frame are always \texttt{0} to keep a certain alignment in the memory which increases the efficiency.
\hfill \break

\paragraph{Stack alignment.}
\label{par:Stack alignment}

We had multiple choices for the implementation of this property. One of them was to modify the main function of the protected program in order to align the return addresses locations correctly. Another idea was to modify the prelude of a program, the prelude is a piece of code created by the compilers which is executed before the program. It is necessary for any program to have this prelude to work correctly. \\
Eventually we chose to introduce before the \textit{main} function of the program an artificial \textit{main}. Its role is to align the stack in order to make all the incoming return addresses locations to match our formula $a~mod~n=0$. \\
Since we have to modify the stack structure we did our transformation at the assembly level(ASM) of CompCert. Indeed the stack pointer ESP which is responsible for the stack growth is only available in ASM. ASM is the lowest level before binary code, though it is difficult to modify ASM correctly since you have to manipulate low level objects. 
By creating a separate artificial \textit{main} function we avoid taking the risk of bugging the prelude or the program's \textit{main} function.\\
This approach has one definite advantage over the others solutions listed before. 
By introducing an artificial \textit{main} we make a clear separation with the code of the program like the original \textit{main} and the prelude. Combining the fact that the original \textit{main} and the prelude might have complicated behaviour and that we do the transformation at a low level.
It is much safer to create a whole new function which can help us avoid introducing bugs in the assembly. The biggest downside is that we have to implement the whole function routine and the call to the original \textit{main} by ourselves in ASM instead of relying on CompCert to do the work.


Figure~\ref{stack_align} represents the stack alignment transformation. The left stack is CompCert stack with fixed frames size equal to $n=2^8$ like we had in the previous section. From this stack we show the consequences of our operation. We insert before the \textit{main} function of the program an artificial \textit{main}. Thus the frame of this artificial \textit{main} is the first frame of the whole stack. The artificial \textit{main} objective is to align the stack in order to have the next return address location $a$ equal to $a~mod~n=0$. \\
We can see on the left stack the effect of the transformation. The return address of \textit{main} was previously at the address \texttt{0xfffff910} and is now at \texttt{0xfffff700}. Since the frames size remained constant we now have all the following return addresses locations verifying $a~mod~n=0$. This was the objective of the whole stack transformation which is now completed.
The downside of this implementation can be seen clearly on the Figure~\ref{stack_align}. Indeed all the return addresses locations verify $a~mod~n=0$ except the return address of the artificial \textit{main} we introduced.
Since our approach aims to protect the locations verifying $a~mod~n=0$, this return address is vulnerable.
Nevertheless, to reach this location an attacker would need to either know the exact location either overwrite the whole stack.
\begin{itemize}
	\item To pinpoint the location of vulnerable return address is really difficult, it would requires a lot of tries and fails or luck. Furthermore, nowadays most of the systems have a security feature called ASLR which inserts randomness in the memory addresses like the stack location. It means that every time a program is executed the location of this return address will be different which complicates the attack. Another possibility is to add in our runtime checks an extra condition to protect this specific return address.
	\item The other way to reach this unprotected return address is prevented by our implementation. The attacker would need to overwrite other frames return address to reach the vulnerable one. In this case our approach will make the program crash before it can arrive at the artificial \textit{main} frame.
\end{itemize}

\begin{figure}[!ht]
\centering
\includegraphics[scale=0.6]{images/stack_align.pdf}
\caption{Aligning CompCert stack frames}
\label{stack_align}
\end{figure}

\paragraph{Alignment algorithm.}
\label{par:Alignment algorithm}
We present in Figure~\ref{align_algo}, the algorithm used to calculate the right size in order to have the next return addresses aligned even with ASLR. The algorithm is written in pseudo assembly code.

The easiest way to understand it is to go through it with an example. On the previous examples Figure~\ref{stack_transform} and Figure~\ref{stack_align} our stack started at the value \texttt{0xfffff910}. Hence for the continuity we will keep this value. 
In Figure~\ref{stack_align} we want to have our next frame starting at the address \texttt{0xfffff700}. 
We go through the different lines of Figure~\ref{align_algo} to explain the algorithm.
\textit{next\_frame} corresponds to the value of the stack pointer which gives the starting address of the following frame.
The aim of the alignment algorithm is to verify the property $\textit{next\_frame}~mod~n=0$ for any initial value of \textit{next\_frame} given by ASLR. For the example we will take \textit{next\_frame}~=~\texttt{0xfffff840}.\\

\begin{enumerate}
	\item we copy the initial \textit{next\_frame} location into a register called \textit{reg}.\\
		  The operation is then \textit{reg}~=~\textit{next\_frame}~=~\texttt{0xfffff840}
	\item \textit{reg} = \textit{reg} \& $(n-1)$ = \texttt{0xfffff840} \& \texttt{0x000000ff} = \texttt{0x00000040}\\
		In our examples we have $n-1 = 2^8-1$ = \texttt{0x000000ff}
	\item \textit{reg} = \textit{reg} $+(n-4)$ = \texttt{0x0000040} $+$ \texttt{0x000000fc} = \texttt{0x00000140}
	\item \textit{next\_frame} $=$ \textit{next\_frame} $-$ \textit{reg} = \texttt{0xfffff840} $-$ \texttt{0x00000140} $=$ \texttt{0xfffff700}
	\item We start the function call routine, here we save registers state in the stack
	\item We store the parameters of the original \textit{main} in the stack
	\item We call the original \textit{main} function, its frame will start at the location stored in \textit{next\_frame}~$=$~\texttt{0xfffff700}
\end{enumerate}

A small remark on the example is that our algorithm only works if the last bit of the first value of \textit{next\_frame} = \texttt{0xfffff840} is \texttt{0}. However this particularity is already present in all compilers since it improves the speed of execution and then our algorithm works with all standard addresses.
\begin{figure}[!ht]
\centering
\begin{lstlisting}
move	reg		next_frame  
and	reg		n-1	    
add	reg		n-4    
sub 	next_frame	reg
store 	regs_state
store	parameters
call	main
	
\end{lstlisting}
\caption{Alignment algorithm}
\label{align_algo}
\end{figure}

\subsubsection{Detection of memory write statements}
\label{ssub:Detection of memory write statements}

\paragraph{Clight implementation.}
\label{par:Clight implementation}

We chose to implement the detection of dangerous statements and also the runtime checks of those statements at the Clight level.
This choice is explained by the fact that Clight is a high-level language in the compilation steps of CompCert (it is the closest to C so the syntax is really similar).
Indeed, doing our transformations at a high-level is much easier since all the complex compilation operations are done later in the process.
For example by using Clight we do not need to bother with low-level objects like registers which if misused can modify the program unexpectedly.
Furthermore Clight is a compilation step placed before any optimization of CompCert.
This means that our implementation can be optimized automatically by CompCert which can improve our performances.

\paragraph{Clight semantic.}
\label{par:Clight semantic}

We have to make sure that we cover all possibly harmful statements with our runtime protection.
Since we are working with the compiler CompCert we are going to take advantage of it.
CompCert has multiple compilation steps which have all been proven from C to assembly language.
To make these proofs, a semantic was defined for each language of the compilation. The semantics all relate to the memory model briefly described in Section~\ref{sub:sfi_comp}.
To detect all dangerous statements we looked at the semantic of Clight and found all statements that in the memory model could write freely in the memory.\\

\begin{figure}[!ht]
\centering
\begin{lstlisting}[language=Caml]
Inductive statement : Type :=
  | Sskip : statement
    (**r do nothing *)
  | Sassign : expr -> expr -> statement
    (**r assignment [lvalue = rvalue] *)
  | Sset : ident -> expr -> statement 
    (**r assignment [tempvar = rvalue] *)
  | Scall: option ident -> expr -> list expr -> statement
    (**r function call *)
  | Sbuiltin: option ident -> external_function -> typelist -> list expr -> statement
    (**r builtin invocation *)
  | Ssequence : statement -> statement -> statement 
    (**r sequence *)
  | Sifthenelse : expr  -> statement -> statement -> statement
    (**r conditional *)
  | Sloop: statement -> statement -> statement 
    (**r infinite loop *)
  | Sbreak : statement   
    (**r [break] statement *)
  | Scontinue : statement
    (**r [continue] statement *)
  | Sreturn : option expr -> statement 
    (**r [return] statement *)
  | Sswitch : expr -> labeled_statements -> statement
    (**r [switch] statement *)
  | Slabel : label -> statement -> statement
  | Sgoto : label -> statement
\end{lstlisting}
\caption{Clight statements}
\label{clight_statements}
\end{figure}

In Figure~\ref{clight_statements}, we have exposed all the Clight statements. Among them we are going to focus on the ones that change the state of the memory. When looking at the semantic given to these statements, only four of them can change the state of the memory: \textit{Sassign}, \textit{Sbuiltin}, \textit{Sreturn} and \textit{Sskip}.

\begin{itemize}
	\item \textbf{\textit{Sassign}}, are used to assign value to variables, it could be considered as an equivalent of ``='' in C. These statements will be targeted by our approach.
	\item \textbf{\textit{Sbuiltin}}, are used to call builtin functions, which are functions created by CompCert that will be expanded later in the compilation. These statements call functions we trust, that is why we will not consider them as dangerous. We could also look at the builtin functions and modify their code to make them safe.
	\item \textbf{\textit{Sreturn}}, these statements invoke the function call routine. They are also trusted statements, we will not need to add runtime checks on them.
	\item \textbf{\textit{Sskip}}, in certain cases these statements are used to pop the stack. This does not endanger return addresses, we will not concern ourselves with them.
\end{itemize}

Among all the statements, our security checks will only apply to the \textit{Sassign} statements.
Furthermore we can limit ourselves to \textit{Sassign} statements whose left expression can write directly in the memory (``Sassign left\_expr right\_expr'' $\leftrightarrow$ ``left\_expr = right\_expr''). The left expressions targeted are then mostly pointers dereference. To be sure that we have all the dangerous instructions, we reiterate the same approach and we take a look at the semantic of the left expressions in Clight.\\
After checking the semantic of the left expressions, only two types of expressions are able to reference a location in the memory.

\begin{itemize}
	\item \textbf{\textit{Ederef}}, as we predicted these expressions dereference pointers and will be targeted by our approach.
	\item \textbf{\textit{Efield}}, they refer to fields of structure and can also point to locations in the memory. These expressions will also be secured with runtime checks.
\end{itemize}

We finally have defined the profile of the dangerous statements that have to be targeted by our approach. To sum it up, the targeted statements are all the \textit{Sassign} whose left expression is either \textit{Ederef} or \textit{Efield}.

Now that we can detect the dangerous statements we will now add the runtime checks in the Clight code which will terminate our implementation.

\subsubsection{Securing memory write statements}
\label{ssub:implem_check_address}
We want to add a protection mechanism which prevents any dangerous statement from writing on a return address location. These return addresses locations have two special traits:
\begin{enumerate}
	\item they only exist in the memory area of the stack
	\item thanks to our previous modifications, their locations $a$ verify $a~mod~n=0$
\end{enumerate}
If a statement try to write on an address with these two properties then it is an illegal execution and our mechanism will trigger an error behaviour like crashing. The Figure~\ref{runtime_check} explained earlier can be used as a reminder of the principle of these runtime checks.

\paragraph{Distinguish stack and heap addresses.}
\label{par:Distinguish stack or heap}
A program can only use the stack and the heap to store data during runtime. Since return addresses are only present in the stack we need a way to differentiate stack and heap addresses.
In x86 architecture, the stack usually grows downwards in direction of the heap. Therefore the addresses of the stack occupy the high addresses and the heap the low ones. 
The idea is to divide the memory space for the program data into two distinct part. The high addresses for the stack and the low for the heap. \\
We defined the clear separation at the address \texttt{0xff000000}. Every address bigger than \texttt{0xff000000} is considered as part of the stack. Reciprocally every address smaller is part of the heap.
To ensure that either the stack or the heap grows too much and exceeds their designed area we want to put a guard area in the memory. The idea is to define a specific area in the memory, for example [\texttt{0xee000000 - \texttt{0xff000000}}], where it is forbidden to write. If an instruction writes illegally in the guard area the program will detect it and will crash.\\
The principle is represented in Figure~\ref{guard}. Indeed we can see that the stack and the heap are clearly separated by the guard area located between [\texttt{0xee000000 - \texttt{0xff000000}}]. Thus we are sure that every address above \texttt{0xff000000} are part of the stack.

\begin{figure}[!ht]
\centering
\includegraphics[scale=0.6]{images/guard.pdf}
\caption{Guard area for the memory}
\label{guard}
\end{figure}

To detect the write in the guard one possible way is to initialize the area with 0 for example. If we detect a bit in the guard area with the value 1 then we know that the guard has been corrupted and we make the program crash. Since our approach protects against ROP attacks, which takes effect when returning from a function, it is adequate to check the integrity of the guard area at the end of each function before returning.
To be honest the guard area has not been implemented yet. Most of the programs do not have a stack or a heap which grows enough to exceed the limit of \texttt{0xff000000} so we were able to do satisfactory tests nevertheless. This guard area is necessary for our implementation to be complete and we hope that we will be able to do it during the remaining time of the internship.

\paragraph{Check the property $a~mod~n=0$.}
\label{par:Classic check}
 
The second step of the runtime check is to see if the targeted address location $a$ verifies $a~mod~n=0$.
The algorithm used is represented in Figure~\ref{classic_check} with pseudo Clight.
\begin{itemize}
	\item At line~1 we reduce the targeted address to its $log_2(n)$ least significant bits (8 if $n=2^8)$.
Since $n$ is a power of two just comparing the least significant bits to $0$ is equivalent to checking if the address verifies $a~mod~n=0$.
For example we know that the return addresses locations of our previous example Figure~\ref{stack_align} were \texttt{0xfffff700}, \texttt{0xfffff600}, \texttt{0xfffff500}\dots
We can notice that we only need to check if the last eight bits (the last two digit in hexadecimal \texttt{00} in our example) of an address is equal to 0.
If it is we know for sure that the targeted location is a return address.\\
For a random authorized location \texttt{0xfffff7a2} and a return address location \texttt{0xfffff700} with $n=2^8$, we would have to compare \texttt{0x000000a2}(authorized) and \texttt{0x00000000}(unauthorized) with $0$. 
	\item Line~2 we actually see that we do not compare the previous calculated value with 0 but 3. The reason is that return addresses are four bytes long.
		It means that the space taken by a return address located at \texttt{0xfffff700} would be [\texttt{0xfffff700}~-~\texttt{0xffff703}]. It is logical for us to protect the whole return address space, that is why we check if the targeted address least significant bits are smaller than 3.
	\item Line~3 is executed when there is an illegal behaviour. Currently our error behaviour is to make the program crash by trying to write over some protected memory located at the address 0 which triggers a \textit{Segmentation fault}.
	\item Finally line~5 if we successfully pass the verification we are allowed to write on the dereferenced pointer \textit{temp\_var}.
\end{itemize}

\begin{figure}[!ht]
\centering
\begin{lstlisting}[language=C]
	temp_var = targeted_address & (n-1);
	if (temp_var < 3) {
		Error behaviour
	} 
	*targeted_address = value;
	Continue execution...
\end{lstlisting}
\caption{Second test of the protection mechanism}
\label{classic_check}
\end{figure}

Currently our protection mechanism use two \textit{if \dots then \dots else} operation in a row to protect the return addresses. The first to check if the address is in the stack and the second to check the equality $a~mod~n=0$.
However, this kind of control-flow operations are usually quite expensive for the processor. Furthermore we might have to inject our protection mechanism a considerable number of times for a program using a lot of pointer operations.
Hence we present in the next section an alternative to the classic \textit{if then else} called branchless statement.

\paragraph{Branchless check.}
\label{par:Branchless check}

We wanted to limit the overhead introduced by our approach by trying another way to make the protection mechanism. 

Branchless code allows one to create code with the same behaviour as a classic \textit{if then else} but without creating any branch for the processor. In other words the processor will not need to execute different code depending of the condition, the code will be linear.\\
The best way to understand it is to have an example and we show the branchless version of implementation of the protection mechanism in Figure~\ref{branchless}.

The branchless code presented reproduces the second test which checks if the least significant bits of an address is smaller than 3. 
The aim of this algorithm is that if the address contained in the variable \textit{targeted\_address} is an authorized location then the branchless algorithm from line~1 to line~5 should leave the value in \textit{targeted\_address} unchanged. 
Otherwise if \textit{targeted\_address} is a return address then we want our program to crash, therefore at line~6 \textit{targeted\_address} should have the value 0. \\
Branchless uses a lot of bit arithmetic which may be unfamiliar so we are going to go through every line of Figure~\ref{branchless} with two different initial value of \textit{targeted\_address}: one is a return address location which is illegal and the other is an authorized address:

\begin{figure}[!ht]
\centering
\begin{lstlisting}
temp_var = targeted_address & (n-1);
temp_var = temp_var - 3;
temp_var = temp_var >> 31;
temp_var = ~temp_var;
targeted_address = temp_var & targeted_address;
*targeted_address = value;
Continue execution...
\end{lstlisting}
\caption{Branchless version of the second check}
\label{branchless}
\end{figure}

\begin{enumerate}
	\item We keep $n=2^8$ for the chosen frames size. Same as in the previous check we want to make our test on the least significant bits of \textit{targeted\_address}.
		\begin{itemize}
			\item the illegal execution, \textit{targeted\_address} is a return address location, we take \textit{targeted\_address}~=~\texttt{0xfffff700} which gives \textit{temp\_var}~=~\texttt{0x00000000}.
			\item the safe execution, we take \textit{targeted\_address}~=~\texttt{0xfffff7a2} which gives \textit{temp\_var}~=~\texttt{0x000000a2}.
		\end{itemize}
	\item A simple subtraction.
		\begin{itemize}
			\item We have \textit{temp\_var}~=~\textit{temp\_var}~-~3~=~\texttt{0x00000000}~-~\texttt{0x00000003}=~\texttt{0xfffffffd} (signed representation)
			\item \textit{temp\_var}~=~\textit{temp\_var}~-~3~=~\texttt{0x000000a2}~-~\texttt{0x00000003}~=~\texttt{0x0000009f}
		\end{itemize}
	\item We make a right shift bit operation (\texttt{0100} $\rightarrow$ \texttt{0010}) thirty-one times. If the value is negative then the new bits introduced on the left are equal to 1 else they are equal to 0.
		\begin{itemize}
			\item \textit{temp\_var} = \textit{temp\_var} $>>$ 31 = \texttt{0xfffffffd} $>>$ 31 = \texttt{0xffffffff} (because \textit{temp\_var} was negative)
			\item \textit{temp\_var} = \textit{temp\_var} $>>$ 31 = \texttt{0x0000009f} $>>$ 31 = \texttt{0x00000000}
		\end{itemize}
	\item We inverse the value of \textit{temp\_var} (\texttt{0100} $\rightarrow$ \texttt{1011})
		\begin{itemize}
			\item \textit{temp\_var} = $\sim$\textit{temp\_var} = $\sim$\texttt{0xffffffff} = \texttt{0x00000000}
			\item \textit{temp\_var} = $\sim$\textit{temp\_var} = $\sim$\texttt{0x00000000} = \texttt{0xffffffff}
		\end{itemize}
	\item Classic \textit{and} operator (\texttt{0101} \& \texttt{1100} = \texttt{0100})
		\begin{itemize}
			\item \textit{targeted\_address} = \textit{temp\_var} \& \textit{targeted\_address} = \texttt{0x00000000} \& \texttt{0xfffff700} = \texttt{0x00000000}
			\item \textit{targeted\_address} = \textit{temp\_var} \& \textit{targeted\_address} = \texttt{0xffffffff} \& \texttt{0xfffff7a2} = \texttt{0xfffff7a2}
		\end{itemize}
	\item We write on the location we just calculated in \textit{temp\_var}.
		\begin{itemize}
			\item \textit{targeted\_address} was the location of a returned address, it was an illegal behaviour.\\
			We write to the memory location \texttt{0x00000000} which is a protected area. The operation makes the program crash which is what we wanted.
			\item \textit{targeted\_address} was an authorized location. We kept the initial value of \textit{targeted\_address}. \\
				It means that our operation did not change the behaviour of the initial program, the transformation is satisfactory.				
		\end{itemize}
\end{enumerate}

This way we can notice that we got the same result as with the \textit{if then else} check but without creating any branch. In our case it is not possible to make two branchless instead of two \textit{if then else} since even heap addresses would go through the second check which we do not want. \\
Unfortunately for us, the tests that we made showed that the branchless version of our approach was not faster than the classic version it was even slower. Those results will be discussed in details in the next section where we evaluate our implementation.

\subsection{Evaluation of the implementation}
\label{sub:evaluation_of_implem}
Now that our implementation is finished we are going to show the different results we obtained during the internship.

We will show first that our implementation is effective. 
Afterwards we will show different benchmarks we did to measure the cost of our transformations on different criteria like speed or size of the programs.
To conclude we will present multiple ideas on how our approach can still be improved.

\subsubsection{Results}
For the example we are going to confront the buffer overflow presented Figure~\ref{buffer_overflow_code} with our implementation. We modified the code of the buffer overflow a little to simplify the test. To make things easier we just added the function \textit{strcpy} in the program's code instead of calling it from another library. This way the vulnerable code of \textit{strcpy} will be compiled with our transformation and be secured instead of compiling the whole external library.


To check the effectiveness of our approach we compile the buffer overflow in two different ways.
The first time we compile it with our implementation but we do not activate the protection mechanism. 
In other words this executable has fixed frames size but we did not insert the runtime checks so it is still vulnerable to the buffer overflow. 
The second executables is compiled with our whole mechanism and is protected with runtime checks.
However the two executables were compiled with the same stack frames size, $n=2^6$.
The output of the two binaries are presented Figure~\ref{output_weak}~and~\ref{output_protected}. 

\begin{figure}[!ht]
\textcolor{gray}{terminal\$~} ./buff\_comp\_weak \$(python -c 'print "a"*44+"\textbackslash{xb0}\textbackslash{x84}\textbackslash{x04}\textbackslash{x08}"')\\
Address of evil\_code = 0x080484b0 \\

Stack before:\\
0xf756e724   \\
0xff9dab44   \\
0xff9dac74   \\
0x00000002   \\
0xf7731000   \\
\dots\\
0xf75b2d00   \\
             \\
Stack after :\\
0xff9db132   \\
0xff9dab44   \\
0xff9dac74   \\
0x61616161   \\
0x61616161   \\
\dots   \\
0x61616161   \\

Argh, we got hacked!\\
Segmentation fault (core dumped)
\caption{Output from vulnerable CompCert executable}
\label{output_weak}
\end{figure}

Like in Figure~\ref{output_buffer} we can see that we have printed \textit{Argh, we got hacked!} which means we managed to execute the function \textit{evil\_code}. The buffer overflow is successful, we can see that we needed to change the input for the attack to work. Indeed since we changed the compiler and the stack layout the input had to be different to manage the attack. 

\begin{figure}[!ht]
\textcolor{gray}{terminal\$~} ./buff\_comp\_weak \$(python -c 'print "a"*44+"\textbackslash{xc0}\textbackslash{x85}\textbackslash{x04}\textbackslash{x08}"')\\
Address of evil\_code = 0x080485c0\\

Stack before:       \\
0xf7554724          \\
0xff9a88c4          \\
0xff9a8a04          \\
0x00000002          \\
0xf7717000          \\
0000000000          \\
0xf7598d26          \\
0xf7717d60          \\
0x08048654          \\
0xff9a88cc          \\
0xf7598d00          \\
                    \\
Address: 0xffa2b0c0 \\
Segmentation fault (core dumped)
\caption{Output from protected CompCert executable}
\label{output_protected}
\end{figure}

For the sake of the example, we added in the error behaviour a statement which calls  ``\textit{printf(Address: \%p, tmp)}''. In \textit{tmp} we stored the value of the address for which the protection mechanism triggered the error behaviour.
First of all we can see that we made the program crashed before \textit{evil\_code} was executed. Our implementation successfully does what we aimed for, we made the program crash on a dangerous program.
Furthermore we can even see the address on which the program tried to write and was not allowed to. In this example our protection mechanism crashed when the program tried to write on the address $a=\texttt{0xffa2b0c0}$. 
Since the frames size is $n=2^6$ all our return addresses location should have their least six significant bits equal to 0.
We check that $a=\texttt{0xffa2b0c0}$ is effectively a return address. First of all $a>\texttt{0xff000000}$ which means that $a$ is actually part of the stack. Moreover we need to verify the equality $a~mod~n=0 \leftrightarrow (\texttt{0xffa2b0c0})~mod~(\texttt{0x00000040}) = 0$ which is true. 
Both the conditions are fulfilled which means that $a$ is a return address location and that our mechanism properly worked.


\subsubsection{Experimentations}

We mentioned it earlier, we also want to measure the impacts that our transformation may bring in terms of memory and efficiency.
We made some experimentations in order to figure out these questions.
Furthermore we also had to verify which implementation was the most efficient between the branchless and the classic \textit{if then else}.
For our different experimentations we had 74 different C programs which were present within the CompCert project for testing purposes.
The performances of our approach are compared with the original CompCert project whose performances are between \texttt{gcc -O0} and \texttt{gcc -O1} \textcolor{green}{ref}.
For all our executables compiled with fixed frames size we chose the smallest size possible for the programs to be able to run correctly. Our script just try to compile every program with an incrementing frames size until it manages to complete the compilation process.

\paragraph{Efficiency.}
We wanted to measure the efficiency of our different transformations and compare them to the original CompCert. During our test we measured four different implementations: the original CompCert, our transformation just with fixed frames size, with fixed frame size and classic \textit{if then else} runtime checks and the branchless version.
To calculate the execution time we used the Unix utility \textit{time}.
The results are presented in the following graph Figure~\ref{time_graph}.
For more relevant results we removed from all the tested programs the ones whose execution time was too short because the Unix utility \textit{time} imprecision could impact the result greatly.
Figure~\ref{time_percentage_graph} is almost the same but we represented the execution time percentage compared to the original CompCert.

\begin{figure}[!ht]
\centering
\includegraphics[width=1\textwidth]{images/time_graph.pdf}
\caption{Execution time of tested programs}
\label{time_graph}
\end{figure}

\begin{figure}[!ht]
\centering
\includegraphics[width=1\textwidth]{images/time_percentage_graph.pdf}
\caption{Execution time percentages compared to the original CompCert}
\label{time_percentage_graph}
\end{figure}

We notice that the fixed size frames without protection has usually the same execution time than the original CompCert. 
We deduce that only the protection mechanism introduces overhead during the runtime.
Only in the programs \textit{spectral} and \textit{floats} we had a strange overhead which were clearly superior to the protected versions. 
Since the fixed frames size version is only a reduced version of the protected ones it seems very strange. We suspect that this overhead is due to some kind of misalignment of the addresses, more investigations would be needed to determine the exact reason of this phenomenon.

As for the comparison between the \textit{if then else} and the branchless implementations we were disappointed by the results displayed by the branchless version. Indeed the branchless is slower than the classic \textit{if then else} for most programs. \\
Actually what can makes branching instructions expensive in term of time is due to instructions pipelining. 
The modern processors usually put in their pipelines a dozen of instructions ahead of the executed one. 
The issue with branch like \textit{if then else} is that the processors try to make a prediction on the branch that is going to be executed and start pipelining the predicted branch.
If the prediction is right everything is fine, however if the prediction is wrong the whole pipeline might need to be flushed to execute the program correctly. This pipeline flush slows down the execution greatly which is why \textit{if then else} are considered slow instructions.
However in our implementations these predictions are certainly correct most of the time which would explain that the branching introduces less overhead than the branchless version.

Overall, our implementations are quite slow and some of our test programs even present up to 230\% overhead for the classic \textit{if then else} version. Even if the average is comprised between 100\% and 150\% this is still high. Nevertheless there are still ways to improve our implementations that we will present Section~\ref{ssub:discussion}.



\paragraph{Relation between runtime checks and delay.}
The previous test shows that the implementation which added runtime checks are slower than the one with fixed frames size without protection. We suspect that the number of runtime checks is related to the amount of delay introduced by our transformation. To verify this hypothesis we first calculated the number of runtime checks that was executed by each implementation.
We also separated the runtime checks for addresses of the stack and the heap. Indeed in our implementations addresses from the heap only need to go through one conditional jump whereas for the stack we also check the equality $a~mod~n=0$.
Figure~\ref{occurence_graph} presents the number of time our runtime checks are executed. We narrowed the results to the programs which had a significant amount of runtime checks. 
Most of the programs which have not been represented had no runtime checks added because they did not contain any dangerous instructions.
The number of occurrences are on a logarithm axis since the values had big gaps between them.

\begin{figure}[!ht]
\centering
\includegraphics[width=1\textwidth]{images/occurence_graph.pdf}
\caption{Number of runtime checks executed per program}
\label{occurence_graph}
\end{figure}

First of all most of the programs write in the stack, only two of them write in the heap and most of them do not execute any dangerous instructions. Also some of the programs that had overheads in the previous figures also executes a lot runtime checks.
Especially we can notice that the program which had the most overhead \textit{sha3} in Figure~\ref{time_graph} is also the one which executed the most runtime checks $4,5*10^8$. \\
Following this observation we wanted to correlate the overhead introduced with the number of runtime checks executed.
We drew another graph Figure~\ref{correlation_graph} representing the percentage of delay introduced in each program depending of the number of runtime checks added. Like before the number of runtime checks axis uses a logarithmic scale to include all obtained values.

\begin{figure}[!ht]
\centering
\includegraphics[width=1\textwidth]{images/correlation_graph.pdf}
\caption{Evolution of the overhead percentage depending of the number of runtime checks executed}
\label{correlation_graph}
\end{figure}
For this graph we selected only programs that had a significant amount of execution time so the percentage of overhead calculated is not too biased due to the precision of our tool (\textit{time} Unix utility). 
Furthermore among these programs we only selected the one which had executed some runtime checks during their runtime. 
After the selection we were only left with seven programs which is a bit little to make a graph but the results are presented Figure~\ref{correlation_graph}.

We effectively see the percentage of overhead increasing with the number of runtime checks executed.
Despite of the low number of measures, Figure~\ref{correlation_graph} presents the expected characteristic and confirm our hypothesis that the runtime checks impact the most the execution time of the programs.


\paragraph{Stack frames size.}
Another figure we thought would be interesting was to see the distribution of the minimal frames size necessary for the programs to run. These data are represented Figure~\ref{frame_size_graph}.

\begin{figure}[!ht]
\centering
\includegraphics[width=1\textwidth]{images/frame_size_graph.pdf}
\caption{Distribution of the minimum frames size among 74 test programs}
\label{frame_size_graph}
\end{figure}

This gives us an idea about the size of the stack in the protected implementations. The results obtained show the minimal frames size required for our programs are small enough to not impact the memory usage. However the test programs we used were all relatively small and the distribution of bigger programs could be different.
A more interesting graph related to memory consumption would be the comparison of the stack maximum growth between our implementations and the original CompCert. 
%Unfortunately we did not find the time for this experimentation during the span of the internship and we hope to do it during the remaining month.

\subsubsection{Discussion}
\label{ssub:discussion}

In this section we are going to talk about some points that our implementation is still lacking and also ways to improve our implementation that we could explore in the future.

\paragraph{More tests.}
\label{par:More tests}
Our implementation protect return addresses by modifying the stack layout of the programs. With this guarantee we are confident that we can prevent any kind of ROP attacks. 
However we only tested our implementation with simple buffer overflows, to show that our approach is correct it would be interesting to pit our protection mechanisms against more complicated ROP attacks. Otherwise we used CompCert so that eventually we will prove the security properties of our approach . This would be an even more convincing way to affirm the benefits of our approach.

%Another test that is lacking was mentioned before. To have an idea of the impacts of our implementation of the memory consumption it would be interesting to compare the stack growth of a normal program with one compiled with our modified CompCert compiler.

\paragraph{Protection of runtime checks.}
\label{par:Protection of runtime checks}
Actually in our implementation we protect return addresses with runtime checks but we never protect these runtime checks. As in SFI we also need to prevent malicious instructions to avoid going through these checks. Therefore we need to make sure that is not possible for a program to freely jump in the code. This way an attacker would be able to bypass the security measures we established.
In the C language the only expression that could allow such operations would be function pointers. Function pointers allow one to execute the code addressed by the pointer.
The simplest solution would be to totally forbid the usage of function pointers which would solve our issue.
We could also redo the ideas of SFI \textcolor{green}{ref} like creating memory chunks and aligning them in order to render the runtime checks atomic. This idea is similar to our approach, it would need to transform the structure on the memory for the code and then perform runtime checks to make sure we only jump to authorized locations.

\paragraph{Ways of improvement.}
\label{par:Ways of improvement.}
We saw in the earlier section that our implementation was relatively slow compared to the original CompCert. Furthermore the amount of overhead was dependent of the number of runtime checks executed.
The idea would be to reduce the number of runtime checks effectively done.
We can certainly narrow down the number of dangerous statements detected. For example Figure~\ref{harmless} presents some harmless C code that would be protected by our approach but does not present any vulnerability for a ROP attack. The pointer presented here points to an address of the heap so if the heap does not overflow on the stack it's not possible for the pointer \textit{bar} to write on a return address as it is.
We can see clearly that the protection mechanism that will be introduced in this code is not necessary and will just slow down the program.
To detect these kind of occurrences, it would be necessary to make a statistic analysis of the code and pinpoint the statements that present a vulnerability for ROP attacks.
If we could implement such static analyser \textcolor{green}{find ref maybe} the overhead from our implementation will be greatly reduced since we know the more we add runtime checks the more our program will slow down.

\begin{figure}[!ht]
\begin{lstlisting}
void foo(){
	int *bar = malloc(sizeof(int));
	*bar = 1;
}
\end{lstlisting}
\centering
\caption{Example of harmless C code }
\label{harmless}
\end{figure}

\paragraph{Transparency.}
\label{par:Transparency}
Our approach should leave safe programs behaviour unchanged. We do not want our implementation to change harmless programs in any way. Our runtime checks are transparent since the error behaviour is only triggered during illegal executions, otherwise the code executed will stay the same. The other modifications were done at the stack level, the stack does not exist at the level of the C language.
Hence apart from inline assembly (that we want to forbid) it should not be possible to interact with the stack with C. The only way left would be a program which uses direct addressing, in other words a C program which gives raw addresses to pointers like the statement \texttt{pointer = 0xff000022}.
Such program is considered unsafe anyway and with the existence of ASLR the behaviour of the program would be unpredictable.

For these reasons we are confident that our implementation is transparent, but a stronger guarantee would be to give a proof of transparency.

\section{Conclusion}
\label{sec:Conclusion}



\end{document}
%%% Local Variables:
%%% mode: latex
%%% TeX-master:
%%% End:
